{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b89d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41084a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"sink.csv\")\n",
    "\n",
    "# Identify and interpolate missing values\n",
    "data = data.interpolate()\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# Convert the scaled array back to a DataFrame and set the column names\n",
    "data_scaled = pd.DataFrame(data_scaled, columns=data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "194d664f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149585, 45)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52d6ce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_scaled = data_scaled.iloc[:, 1:]\n",
    "\n",
    "# Split data into training, validation, and test sets\n",
    "n_obs = data_scaled.shape[0]\n",
    "train_size = 0.7\n",
    "val_size = 0.15\n",
    "test_size = 0.15\n",
    "\n",
    "trainIndex = np.random.choice(n_obs, size = round(train_size * n_obs), replace = False)\n",
    "trainData = data_scaled.iloc[trainIndex, :]\n",
    "testvalData = data_scaled.iloc[np.setdiff1d(np.arange(n_obs), trainIndex), :]\n",
    "\n",
    "valIndex = np.random.choice(testvalData.shape[0], size = round(val_size * testvalData.shape[0]), replace = False)\n",
    "valData = testvalData.iloc[valIndex, :]\n",
    "testData = testvalData.iloc[np.setdiff1d(np.arange(testvalData.shape[0]), valIndex), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccdc6ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50\n",
      "0.9888227614256744\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"sink.csv\")\n",
    "\n",
    "# Define targets (binary classification problem)\n",
    "data[\"sank\"] = (data[\"sank\"] > 0).astype(int)\n",
    "targets = data[\"sank\"].values\n",
    "\n",
    "# Drop any rows with NaNs\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data.drop(columns=[\"sank\"]).values)\n",
    "\n",
    "# Split data into training, validation, and test sets\n",
    "n_obs = data_scaled.shape[0]\n",
    "train_size = 0.7\n",
    "val_size = 0.15\n",
    "test_size = 0.15\n",
    "\n",
    "trainIndex = np.random.choice(n_obs, size = round(train_size * n_obs), replace = False)\n",
    "trainData = data_scaled[trainIndex, :]\n",
    "trainTargets = targets[trainIndex]\n",
    "testvalData = data_scaled[np.setdiff1d(np.arange(n_obs), trainIndex), :]\n",
    "testvalTargets = targets[np.setdiff1d(np.arange(n_obs), trainIndex)]\n",
    "\n",
    "valIndex = np.random.choice(testvalData.shape[0], size = round(val_size * testvalData.shape[0]), replace = False)\n",
    "valData = testvalData[valIndex, :]\n",
    "valTargets = testvalTargets[valIndex]\n",
    "testData = testvalData[np.setdiff1d(np.arange(testvalData.shape[0]), valIndex), :]\n",
    "testTargets = testvalTargets[np.setdiff1d(np.arange(testvalData.shape[0]), valIndex)]\n",
    "\n",
    "# Train and validate the neural network\n",
    "best_auc = 0\n",
    "for hl in [10, 20, 30, 40, 50, 60]:\n",
    "    for hn in [10, 20, 30, 40, 50, 60]:\n",
    "        clf = MLPClassifier(hidden_layer_sizes=(hl, hn), max_iter=500, random_state=0)\n",
    "        clf.fit(trainData, trainTargets)\n",
    "        val_pred = clf.predict_proba(valData)[:, 1]\n",
    "        val_auc = roc_auc_score(valTargets, val_pred)\n",
    "        if val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            best_hl = hl\n",
    "            best_hn = hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "acf7b7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 60\n",
      "0.9888227614256744\n"
     ]
    }
   ],
   "source": [
    "# Test the neural network\n",
    "clf = MLPClassifier(hidden_layer_sizes=(50, 50), max_iter=500, random_state=0)\n",
    "clf.fit(trainData, trainTargets)\n",
    "test_pred = clf.predict_proba(testData)[:, 1]\n",
    "test_auc = roc_auc_score(testTargets, test_pred)\n",
    "print(test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29f96629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Longitude', 'Latitude', 'AirTempSurface', 'Cloudiness', 'LatentHeat',\n",
      "       'HumidityMinusTemp', 'Humidity', 'HeatParameter', 'Humidity.1',\n",
      "       'Pressure', 'SeaAirTempDiff', 'SeaSurfaceTemp',\n",
      "       'SensibleHeatTransEastward', 'ZonalLatentHeatParameter', 'UWindStress',\n",
      "       'LatentHeatTransEastward', 'UWind', 'SensibleHeatTransNorthward',\n",
      "       'MeridonalLatentHeatParameter', 'VWindStress',\n",
      "       'LatentHeatTransNorthward', 'VWind', 'ScalarWind', 'ScalarWindCubed',\n",
      "       'calcite', 'u_current', 'v_current', 'ice', 'pressure', 'Temperature',\n",
      "       'SurfaceVelocity', 'Temperature.1', 'PotentialDensity', 'UCurrent',\n",
      "       'VCurrent', 'SeaIceConcentration', 'uv_magnitude10',\n",
      "       'MeridonalSurfaceWindStress10', 'curl10', 'uv_magnitude20',\n",
      "       'ZonalSurfaceWindStress20', 'MeridonalSurfaceWindStress20', 'curl20'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('sink.csv') # read in the original dataset\n",
    "# assuming df is your dataframe\n",
    "feature_names = df.columns[1:3].append(df.columns[4:])\n",
    " # get all columns except the last one (which is typically the target variable)\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "223ed2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitude: 0.056843051121418436\n",
      "Latitude: -0.0009578692045793535\n",
      "AirTempSurface: 0.020602952943963828\n",
      "Cloudiness: 9.518859309471329e-05\n",
      "LatentHeat: -0.030998211334352974\n",
      "HumidityMinusTemp: 0.03872318875433142\n",
      "Humidity: -0.015161107025264138\n",
      "HeatParameter: -0.025825357921530546\n",
      "Humidity.1: -0.029194852037949567\n",
      "Pressure: 0.024247822851889908\n",
      "SeaAirTempDiff: -0.02729058014519422\n",
      "SeaSurfaceTemp: -0.005189665442216424\n",
      "SensibleHeatTransEastward: 0.02342614884839932\n",
      "ZonalLatentHeatParameter: -0.031053156218541576\n",
      "UWindStress: -0.0344811732663145\n",
      "LatentHeatTransEastward: -0.016072876161012068\n",
      "UWind: -0.0195676709465081\n",
      "SensibleHeatTransNorthward: 0.001117852423222557\n",
      "MeridonalLatentHeatParameter: 0.007229430794977195\n",
      "VWindStress: 0.02551872522301418\n",
      "LatentHeatTransNorthward: 0.013258316642082919\n",
      "VWind: 0.006282918297360456\n",
      "ScalarWind: 0.03151439718672922\n",
      "ScalarWindCubed: -0.013521687854069627\n",
      "calcite: -0.008502569004255585\n",
      "u_current: 0.009772033376130293\n",
      "v_current: 0.05923074534371144\n",
      "ice: 0.044356018554786304\n",
      "pressure: -0.027900837523177832\n",
      "Temperature: 0.0015019631323319371\n",
      "SurfaceVelocity: 0.08172105685109926\n",
      "Temperature.1: -0.03812244476378518\n",
      "PotentialDensity: 0.05280094441464021\n",
      "UCurrent: -0.04958416763851827\n",
      "VCurrent: -0.024189272847385437\n",
      "SeaIceConcentration: -0.028510070467589358\n",
      "uv_magnitude10: -0.005067031616769055\n",
      "MeridonalSurfaceWindStress10: -0.008448536162723168\n",
      "curl10: 0.019504561682897836\n",
      "uv_magnitude20: 0.05019245483035831\n",
      "ZonalSurfaceWindStress20: 0.0010877303476754363\n",
      "MeridonalSurfaceWindStress20: 0.01843847709369295\n",
      "curl20: 0.032147648624373915\n"
     ]
    }
   ],
   "source": [
    "# Get feature importances\n",
    "importances = clf.coefs_[0]\n",
    "# Print feature importances\n",
    "for i in range(len(feature_names)):\n",
    "    print(f\"{feature_names[i]}: {importances[i].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "72343d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Feature  Importance\n",
      "30               SurfaceVelocity    0.081721\n",
      "26                     v_current    0.059231\n",
      "0                      Longitude    0.056843\n",
      "32              PotentialDensity    0.052801\n",
      "39                uv_magnitude20    0.050192\n",
      "27                           ice    0.044356\n",
      "5              HumidityMinusTemp    0.038723\n",
      "42                        curl20    0.032148\n",
      "22                    ScalarWind    0.031514\n",
      "19                   VWindStress    0.025519\n",
      "9                       Pressure    0.024248\n",
      "12     SensibleHeatTransEastward    0.023426\n",
      "2                 AirTempSurface    0.020603\n",
      "38                        curl10    0.019505\n",
      "41  MeridonalSurfaceWindStress20    0.018438\n",
      "20      LatentHeatTransNorthward    0.013258\n",
      "25                     u_current    0.009772\n",
      "18  MeridonalLatentHeatParameter    0.007229\n",
      "21                         VWind    0.006283\n",
      "29                   Temperature    0.001502\n",
      "17    SensibleHeatTransNorthward    0.001118\n",
      "40      ZonalSurfaceWindStress20    0.001088\n",
      "3                     Cloudiness    0.000095\n",
      "1                       Latitude   -0.000958\n",
      "36                uv_magnitude10   -0.005067\n",
      "11                SeaSurfaceTemp   -0.005190\n",
      "37  MeridonalSurfaceWindStress10   -0.008449\n",
      "24                       calcite   -0.008503\n",
      "23               ScalarWindCubed   -0.013522\n",
      "6                       Humidity   -0.015161\n",
      "15       LatentHeatTransEastward   -0.016073\n",
      "16                         UWind   -0.019568\n",
      "34                      VCurrent   -0.024189\n",
      "7                  HeatParameter   -0.025825\n",
      "10                SeaAirTempDiff   -0.027291\n",
      "28                      pressure   -0.027901\n",
      "35           SeaIceConcentration   -0.028510\n",
      "8                     Humidity.1   -0.029195\n",
      "4                     LatentHeat   -0.030998\n",
      "13      ZonalLatentHeatParameter   -0.031053\n",
      "14                   UWindStress   -0.034481\n",
      "31                 Temperature.1   -0.038122\n",
      "33                      UCurrent   -0.049584\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe with feature names and importances\n",
    "df_importances = pd.DataFrame({'Feature': feature_names, 'Importance': [importances[i].mean() for i in range(len(feature_names))]})\n",
    "\n",
    "# Sort the dataframe by importance, in descending order\n",
    "df_importances = df_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Print the sorted dataframe\n",
    "print(df_importances)\n",
    "df_importances.to_csv(\"2nn_importances.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43a8a800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.37\n",
      "Accuracy Score: 0.9981386325503355\n",
      "Confusion Matrix:\n",
      " [[37948    21]\n",
      " [   50   125]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Try different threshold values\n",
    "thresholds = np.arange(0.1, 1.0, 0.01)\n",
    "best_threshold = None\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # Convert test_pred and testTargets to binary variables\n",
    "    test_pred_binary = [1 if x >= threshold else 0 for x in test_pred]\n",
    "    testTargets_binary = [1 if x >= threshold else 0 for x in testTargets]\n",
    "\n",
    "    # Calculate accuracy score\n",
    "    accuracy = accuracy_score(testTargets_binary, test_pred_binary)\n",
    "\n",
    "    # Update best threshold and accuracy if necessary\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_threshold = threshold\n",
    "\n",
    "# Convert test_pred and testTargets to binary variables using the best threshold\n",
    "test_pred_binary = [1 if x >= best_threshold else 0 for x in test_pred]\n",
    "testTargets_binary = [1 if x >= best_threshold else 0 for x in testTargets]\n",
    "\n",
    "# Get accuracy score\n",
    "accuracy = accuracy_score(testTargets_binary, test_pred_binary)\n",
    "print(\"Best Threshold:\", round(best_threshold, 2))\n",
    "print(\"Accuracy Score:\", accuracy)\n",
    "\n",
    "# Get confusion matrix\n",
    "cm = confusion_matrix(testTargets_binary, test_pred_binary)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d31fb70b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(60, 60, 60), max_iter=500, random_state=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f27b381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "0.9878935823585406\n"
     ]
    }
   ],
   "source": [
    "# Train and validate the neural network\n",
    "best_auc = 0\n",
    "for hl in [10, 20, 30, 40, 50, 60]:\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(hl, hn), max_iter=500, random_state=0)\n",
    "    clf.fit(trainData, trainTargets)\n",
    "    val_pred = clf.predict_proba(valData)[:, 1]\n",
    "    val_auc = roc_auc_score(valTargets, val_pred)\n",
    "    if val_auc > best_auc:\n",
    "        best_auc = val_auc\n",
    "        best_hl = hl\n",
    "        best_hn = hn\n",
    "\n",
    "# Test the neural network\n",
    "clf1 = MLPClassifier(hidden_layer_sizes=(best_hl), max_iter=500, random_state=0)\n",
    "clf1.fit(trainData, trainTargets)\n",
    "test_pred = clf1.predict_proba(testData)[:, 1]\n",
    "test_auc = roc_auc_score(testTargets, test_pred)\n",
    "print(best_hl)\n",
    "print(test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f27f13a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.38\n",
      "Accuracy Score: 0.9972734899328859\n",
      "Confusion Matrix:\n",
      " [[37938    31]\n",
      " [   73   102]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Try different threshold values\n",
    "thresholds = np.arange(0.1, 1.0, 0.01)\n",
    "best_threshold = None\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # Convert test_pred and testTargets to binary variables\n",
    "    test_pred_binary = [1 if x >= threshold else 0 for x in test_pred]\n",
    "    testTargets_binary = [1 if x >= threshold else 0 for x in testTargets]\n",
    "\n",
    "    # Calculate accuracy score\n",
    "    accuracy = accuracy_score(testTargets_binary, test_pred_binary)\n",
    "\n",
    "    # Update best threshold and accuracy if necessary\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_threshold = threshold\n",
    "\n",
    "# Convert test_pred and testTargets to binary variables using the best threshold\n",
    "test_pred_binary = [1 if x >= best_threshold else 0 for x in test_pred]\n",
    "testTargets_binary = [1 if x >= best_threshold else 0 for x in testTargets]\n",
    "\n",
    "# Get accuracy score\n",
    "accuracy = accuracy_score(testTargets_binary, test_pred_binary)\n",
    "print(\"Best Threshold:\", round(best_threshold, 2))\n",
    "print(\"Accuracy Score:\", accuracy)\n",
    "\n",
    "# Get confusion matrix\n",
    "cm = confusion_matrix(testTargets_binary, test_pred_binary)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30cd0ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "0.9908996436942921\n"
     ]
    }
   ],
   "source": [
    "# Train and validate the neural network\n",
    "best_auc = 0\n",
    "for h1 in [10, 20, 30, 40, 50, 60]:\n",
    "    for h2 in [10, 20, 30, 40, 50, 60]:\n",
    "        for h3 in [10, 20, 30, 40, 50, 60]:\n",
    "            clf = MLPClassifier(hidden_layer_sizes=(h1, h2, h3), max_iter=500, random_state=0)\n",
    "            clf.fit(trainData, trainTargets)\n",
    "            val_pred = clf.predict_proba(valData)[:, 1]\n",
    "            val_auc = roc_auc_score(valTargets, val_pred)\n",
    "            if val_auc > best_auc:\n",
    "                best_auc = val_auc\n",
    "                best_hl = hl\n",
    "                best_hn = hn\n",
    "\n",
    "# Test the neural network\n",
    "clf3 = MLPClassifier(hidden_layer_sizes=(best_hl), max_iter=500, random_state=0)\n",
    "clf3.fit(trainData, trainTargets)\n",
    "test_pred = clf3.predict_proba(testData)[:, 1]\n",
    "test_auc = roc_auc_score(testTargets, test_pred)\n",
    "print(best_hl)\n",
    "print(test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0104e78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.51\n",
      "Accuracy Score: 0.9972472734899329\n",
      "Confusion Matrix:\n",
      " [[37938    31]\n",
      " [   74   101]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Try different threshold values\n",
    "thresholds = np.arange(0.1, 1.0, 0.01)\n",
    "best_threshold = None\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # Convert test_pred and testTargets to binary variables\n",
    "    test_pred_binary = [1 if x >= threshold else 0 for x in test_pred]\n",
    "    testTargets_binary = [1 if x >= threshold else 0 for x in testTargets]\n",
    "\n",
    "    # Calculate accuracy score\n",
    "    accuracy = accuracy_score(testTargets_binary, test_pred_binary)\n",
    "\n",
    "    # Update best threshold and accuracy if necessary\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_threshold = threshold\n",
    "\n",
    "# Convert test_pred and testTargets to binary variables using the best threshold\n",
    "test_pred_binary = [1 if x >= best_threshold else 0 for x in test_pred]\n",
    "testTargets_binary = [1 if x >= best_threshold else 0 for x in testTargets]\n",
    "\n",
    "# Get accuracy score\n",
    "accuracy = accuracy_score(testTargets_binary, test_pred_binary)\n",
    "print(\"Best Threshold:\", round(best_threshold, 2))\n",
    "print(\"Accuracy Score:\", accuracy)\n",
    "\n",
    "# Get confusion matrix\n",
    "cm = confusion_matrix(testTargets_binary, test_pred_binary)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bdf731b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "60\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "print(h1)\n",
    "print(h2)\n",
    "print(h3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
